{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7040858e",
   "metadata": {},
   "source": [
    "# Faster R-CNN Training for PPE Detection\n",
    "\n",
    "## Configuration\n",
    "- **Model**: Faster R-CNN with ResNet50-FPN backbone\n",
    "- **Optimizer**: SGD (lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "- **Batch Size**: 16\n",
    "- **Epochs**: 100\n",
    "- **Scheduler**: StepLR (reduce lr by 50% every 20 epochs)\n",
    "- **Dataset**: PPE Detection Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe6c9d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc5c0e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.ops as ops\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5666da7",
   "metadata": {},
   "source": [
    "## 2. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dcefee",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class PPEDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        with open(os.path.join(root_dir, 'data.yaml'), 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        self.class_names = data_config['names']\n",
    "        self.num_classes = data_config['nc']\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.img_dir = os.path.join(root_dir, 'train_aug', 'images')\n",
    "            self.label_dir = os.path.join(root_dir, 'train_aug', 'labels')\n",
    "        else:\n",
    "            self.img_dir = os.path.join(root_dir, 'valid', 'images')\n",
    "            self.label_dir = os.path.join(root_dir, 'valid', 'labels')\n",
    "        \n",
    "        self.img_files = [f for f in os.listdir(self.img_dir) if f.endswith('.jpg')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        label_path = os.path.join(self.label_dir, self.img_files[idx].replace('.jpg', '.txt'))\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        parts = line.split()\n",
    "                        class_id = int(float(parts[0]))\n",
    "                        x_center, y_center, width, height = map(float, parts[1:])\n",
    "                        \n",
    "                        if width <= 0 or height <= 0:\n",
    "                            continue\n",
    "                        \n",
    "                        img_width, img_height = image.size\n",
    "                        x_min = (x_center - width/2) * img_width\n",
    "                        y_min = (y_center - height/2) * img_height\n",
    "                        x_max = (x_center + width/2) * img_width\n",
    "                        y_max = (y_center + height/2) * img_height\n",
    "                        \n",
    "                        x_min = max(0, min(x_min, img_width))\n",
    "                        y_min = max(0, min(y_min, img_height))\n",
    "                        x_max = max(0, min(x_max, img_width))\n",
    "                        y_max = max(0, min(y_max, img_height))\n",
    "                        \n",
    "                        if x_max > x_min and y_max > y_min:\n",
    "                            boxes.append([x_min, y_min, x_max, y_max])\n",
    "                            labels.append(class_id + 1)\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx])\n",
    "        }\n",
    "        \n",
    "        image_tensor = F.to_tensor(image)\n",
    "        return image_tensor, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d056c1",
   "metadata": {},
   "source": [
    "## 3. Model and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40953390",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    \"\"\"Create Faster R-CNN model with custom number of classes\"\"\"\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to filter invalid boxes\"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    filtered_images = []\n",
    "    filtered_targets = []\n",
    "    \n",
    "    for img, target in zip(images, targets):\n",
    "        if len(target['boxes']) > 0:\n",
    "            valid_boxes = []\n",
    "            valid_labels = []\n",
    "            \n",
    "            for i, box in enumerate(target['boxes']):\n",
    "                x1, y1, x2, y2 = box\n",
    "                if x2 > x1 and y2 > y1:\n",
    "                    valid_boxes.append(box)\n",
    "                    valid_labels.append(target['labels'][i])\n",
    "            \n",
    "            if len(valid_boxes) > 0:\n",
    "                filtered_target = {\n",
    "                    'boxes': torch.stack(valid_boxes),\n",
    "                    'labels': torch.stack(valid_labels),\n",
    "                    'image_id': target['image_id']\n",
    "                }\n",
    "                filtered_images.append(img)\n",
    "                filtered_targets.append(filtered_target)\n",
    "    \n",
    "    return list(filtered_images), list(filtered_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372baf4e",
   "metadata": {},
   "source": [
    "## 4. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c616c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"/root/ocr-project/First/Detection/ppe-dataset-clean/versions/1/ppe-detection-project-dataset-c/versions/1\"\n",
    "\n",
    "with open(os.path.join(dataset_root, 'data.yaml'), 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "class_names = data_config['names']\n",
    "num_classes = data_config['nc']\n",
    "\n",
    "train_dataset = PPEDataset(dataset_root, split='train')\n",
    "val_dataset = PPEDataset(dataset_root, split='val')\n",
    "\n",
    "print(f\"Classes: {num_classes} ({class_names})\")\n",
    "print(f\"Training: {len(train_dataset)} images\")\n",
    "print(f\"Validation: {len(val_dataset)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305d063",
   "metadata": {},
   "source": [
    "## 5. Initialize Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf45775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# Initialize Wandb\n",
    "run = wandb.init(\n",
    "    project=\"ppe-detection-fasterrcnn\",\n",
    "    config={\n",
    "        'batch_size': batch_size,\n",
    "        'num_epochs': num_epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'momentum': momentum,\n",
    "        'weight_decay': weight_decay,\n",
    "        'num_classes': num_classes + 1,\n",
    "    },\n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "wandb.define_metric(\"epoch\")\n",
    "wandb.define_metric(\"train_loss\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"val_loss\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"learning_rate\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"mAP\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"precision\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"recall\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"f1_score\", step_metric=\"epoch\")\n",
    "\n",
    "for class_name in class_names:\n",
    "    wandb.define_metric(f\"mAP_{class_name}\", step_metric=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6561ff",
   "metadata": {},
   "source": [
    "## 6. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb193a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af14ea",
   "metadata": {},
   "source": [
    "## 7. Create Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc7971",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = get_model(num_classes + 1)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "# Learning rate scheduler: reduce LR by 50% every 20 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "print(f\"Model created and moved to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b90b418",
   "metadata": {},
   "source": [
    "## 8. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a916d78",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    metric_logger = {}\n",
    "    \n",
    "    for idx, batch in enumerate(tqdm(data_loader, desc=f'Epoch {epoch}')):\n",
    "        if len(batch) == 2:\n",
    "            images, targets = batch\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "            \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        \n",
    "        if isinstance(loss_dict, dict):\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            for k, v in loss_dict.items():\n",
    "                if k not in metric_logger:\n",
    "                    metric_logger[k] = []\n",
    "                metric_logger[k].append(v.item())\n",
    "        else:\n",
    "            losses = loss_dict\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return {k: np.mean(v) for k, v in metric_logger.items()}\n",
    "\n",
    "def calculate_detection_metrics(predictions, targets, class_names, iou_threshold=0.5):\n",
    "    \"\"\"Calculate mAP, precision, recall, and F1 score\"\"\"\n",
    "    metrics = {}\n",
    "    num_classes = len(class_names)\n",
    "    aps = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_name = class_names[class_idx]\n",
    "        pred_boxes = []\n",
    "        pred_scores = []\n",
    "        gt_boxes = []\n",
    "        \n",
    "        for pred in predictions:\n",
    "            if 'boxes' in pred and 'labels' in pred and 'scores' in pred:\n",
    "                class_mask = pred['labels'] == (class_idx + 1)\n",
    "                if class_mask.any():\n",
    "                    pred_boxes.append(pred['boxes'][class_mask])\n",
    "                    pred_scores.append(pred['scores'][class_mask])\n",
    "        \n",
    "        for target in targets:\n",
    "            if 'boxes' in target and 'labels' in target:\n",
    "                class_mask = target['labels'] == (class_idx + 1)\n",
    "                if class_mask.any():\n",
    "                    gt_boxes.append(target['boxes'][class_mask])\n",
    "        \n",
    "        if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "            all_pred_boxes = torch.cat(pred_boxes, dim=0)\n",
    "            all_pred_scores = torch.cat(pred_scores, dim=0)\n",
    "            all_gt_boxes = torch.cat(gt_boxes, dim=0)\n",
    "            \n",
    "            if len(all_pred_boxes) > 0 and len(all_gt_boxes) > 0:\n",
    "                ious = ops.box_iou(all_pred_boxes, all_gt_boxes)\n",
    "                sorted_indices = torch.argsort(all_pred_scores, descending=True)\n",
    "                sorted_ious = ious[sorted_indices]\n",
    "                \n",
    "                tp = torch.zeros(len(sorted_ious))\n",
    "                fp = torch.zeros(len(sorted_ious))\n",
    "                gt_matched = torch.zeros(len(all_gt_boxes), dtype=torch.bool)\n",
    "                \n",
    "                for i in range(len(sorted_ious)):\n",
    "                    max_iou, max_idx = torch.max(sorted_ious[i], dim=0)\n",
    "                    if max_iou >= iou_threshold and not gt_matched[max_idx]:\n",
    "                        tp[i] = 1\n",
    "                        gt_matched[max_idx] = True\n",
    "                    else:\n",
    "                        fp[i] = 1\n",
    "                \n",
    "                tp_cumsum = torch.cumsum(tp, dim=0)\n",
    "                fp_cumsum = torch.cumsum(fp, dim=0)\n",
    "                precision = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
    "                recall = tp_cumsum / len(all_gt_boxes)\n",
    "                \n",
    "                # Calculate AP using 11-point interpolation\n",
    "                ap = 0\n",
    "                for t in torch.arange(0, 1.1, 0.1):\n",
    "                    if torch.sum(recall >= t) == 0:\n",
    "                        p = 0\n",
    "                    else:\n",
    "                        p = torch.max(precision[recall >= t])\n",
    "                    ap += p / 11\n",
    "                \n",
    "                metrics[f'mAP_{class_name}'] = ap.item()\n",
    "                aps.append(ap.item())\n",
    "                precisions.append(precision[-1].item() if len(precision) > 0 else 0)\n",
    "                recalls.append(recall[-1].item() if len(recall) > 0 else 0)\n",
    "            else:\n",
    "                metrics[f'mAP_{class_name}'] = 0\n",
    "                aps.append(0)\n",
    "                precisions.append(0)\n",
    "                recalls.append(0)\n",
    "        else:\n",
    "            metrics[f'mAP_{class_name}'] = 0\n",
    "            aps.append(0)\n",
    "            precisions.append(0)\n",
    "            recalls.append(0)\n",
    "    \n",
    "    metrics['mAP'] = np.mean(aps) if aps else 0\n",
    "    metrics['precision'] = np.mean(precisions) if precisions else 0\n",
    "    metrics['recall'] = np.mean(recalls) if recalls else 0\n",
    "    \n",
    "    if metrics['precision'] + metrics['recall'] > 0:\n",
    "        metrics['f1_score'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])\n",
    "    else:\n",
    "        metrics['f1_score'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluate(model, data_loader, device, class_names):\n",
    "    \"\"\"Evaluate model on validation set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            if len(batch) == 2:\n",
    "                images, targets = batch\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            if len(images) == 0:\n",
    "                continue\n",
    "                \n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            predictions = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            model.train()\n",
    "            loss_dict = model(images, targets)\n",
    "            model.eval()\n",
    "            \n",
    "            if isinstance(loss_dict, dict):\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "            else:\n",
    "                losses = loss_dict\n",
    "                \n",
    "            total_loss += losses.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            all_predictions.extend(predictions)\n",
    "            all_targets.extend(targets)\n",
    "    \n",
    "    metrics = calculate_detection_metrics(all_predictions, all_targets, class_names)\n",
    "    metrics['val_loss'] = total_loss / num_batches if num_batches > 0 else 0\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69417dde",
   "metadata": {},
   "source": [
    "## 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training: {num_epochs} epochs, batch size {batch_size}\")\n",
    "print(f\"Learning rate will reduce by 50% every 20 epochs\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    train_metrics = train_one_epoch(model, optimizer, train_loader, device, epoch+1)\n",
    "    val_metrics = evaluate(model, val_loader, device, class_names)\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    total_train_loss = sum(train_metrics.values())\n",
    "    train_losses.append(total_train_loss)\n",
    "    val_losses.append(val_metrics['val_loss'])\n",
    "    learning_rates.append(current_lr)\n",
    "    \n",
    "    # Log to wandb\n",
    "    log_dict = {\n",
    "        'epoch': epoch+1,\n",
    "        'train_loss': total_train_loss,\n",
    "        'val_loss': val_metrics['val_loss'],\n",
    "        'learning_rate': current_lr,\n",
    "        'mAP': val_metrics['mAP'],\n",
    "        'precision': val_metrics['precision'],\n",
    "        'recall': val_metrics['recall'],\n",
    "        'f1_score': val_metrics['f1_score']\n",
    "    }\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        log_dict[f'mAP_{class_name}'] = val_metrics[f'mAP_{class_name}']\n",
    "    \n",
    "    wandb.log(log_dict)\n",
    "    \n",
    "    print(f\"Results:\")\n",
    "    print(f\"  - Train Loss: {total_train_loss:.4f}\")\n",
    "    print(f\"  - Val Loss: {val_metrics['val_loss']:.4f}\")\n",
    "    print(f\"  - Learning Rate: {current_lr:.6f}\")\n",
    "    print(f\"  - mAP: {val_metrics['mAP']:.3f}\")\n",
    "    print(f\"  - Precision: {val_metrics['precision']:.3f}\")\n",
    "    print(f\"  - Recall: {val_metrics['recall']:.3f}\")\n",
    "    print(f\"  - F1 Score: {val_metrics['f1_score']:.3f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81d301",
   "metadata": {},
   "source": [
    "## 10. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "ax2.plot(epochs, learning_rates, 'g-', linewidth=2)\n",
    "ax2.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Learning Rate')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Per-class mAP\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "last_val_metrics = evaluate(model, val_loader, device, class_names)\n",
    "class_maps = [last_val_metrics[f'mAP_{class_name}'] for class_name in class_names]\n",
    "ax3.bar(class_names, class_maps, color='skyblue')\n",
    "ax3.set_title('mAP per Class', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('mAP')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "wandb.log({\"training_progress\": wandb.Image(fig)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac1322",
   "metadata": {},
   "source": [
    "## 11. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb9fe3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_path = 'fasterrcnn_ppe_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "wandb.save(model_path)\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
