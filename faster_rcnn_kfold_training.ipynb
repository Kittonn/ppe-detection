{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f0642c",
   "metadata": {},
   "source": [
    "# Faster R-CNN K-Fold Cross Validation Training\n",
    "\n",
    "## Configuration\n",
    "- **Model**: Faster R-CNN with ResNet50-FPN backbone\n",
    "- **Optimizer**: SGD (lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "- **Batch Size**: 16 (with gradient accumulation 4 steps)\n",
    "- **Effective Batch Size**: 64\n",
    "- **K-Folds**: 5\n",
    "- **Epochs per Fold**: 20\n",
    "- **Scheduler**: StepLR (reduce lr by 50% every 10 epochs)\n",
    "- **Mixed Precision**: Enabled\n",
    "- **Evaluation**: Every 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3296049d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e189b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.ops as ops\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import json\n",
    "from datetime import datetime\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e0beeb",
   "metadata": {},
   "source": [
    "## 2. Combined Dataset Class for K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d112fe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CombinedPPEDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        with open(os.path.join(root_dir, 'data.yaml'), 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        self.class_names = data_config['names']\n",
    "        self.num_classes = data_config['nc']\n",
    "        \n",
    "        # Combine train_aug and valid datasets\n",
    "        self.train_img_dir = os.path.join(root_dir, 'train_aug', 'images')\n",
    "        self.train_label_dir = os.path.join(root_dir, 'train_aug', 'labels')\n",
    "        self.valid_img_dir = os.path.join(root_dir, 'valid', 'images')\n",
    "        self.valid_label_dir = os.path.join(root_dir, 'valid', 'labels')\n",
    "        \n",
    "        train_files = [f for f in os.listdir(self.train_img_dir) if f.endswith('.jpg')]\n",
    "        valid_files = [f for f in os.listdir(self.valid_img_dir) if f.endswith('.jpg')]\n",
    "        \n",
    "        self.img_files = []\n",
    "        self.label_files = []\n",
    "        self.stratified_labels = []\n",
    "        \n",
    "        # Add train files\n",
    "        for f in train_files:\n",
    "            self.img_files.append(os.path.join(self.train_img_dir, f))\n",
    "            label_path = os.path.join(self.train_label_dir, f.replace('.jpg', '.txt'))\n",
    "            self.label_files.append(label_path)\n",
    "            self.stratified_labels.append(self._get_stratified_label(label_path))\n",
    "        \n",
    "        # Add valid files\n",
    "        for f in valid_files:\n",
    "            self.img_files.append(os.path.join(self.valid_img_dir, f))\n",
    "            label_path = os.path.join(self.valid_label_dir, f.replace('.jpg', '.txt'))\n",
    "            self.label_files.append(label_path)\n",
    "            self.stratified_labels.append(self._get_stratified_label(label_path))\n",
    "        \n",
    "        print(f\"Combined dataset: {len(self.img_files)} images\")\n",
    "        print(f\"  - Train images: {len(train_files)}\")\n",
    "        print(f\"  - Valid images: {len(valid_files)}\")\n",
    "    \n",
    "    def _get_stratified_label(self, label_path):\n",
    "        \"\"\"Get stratified label for balanced K-fold split\"\"\"\n",
    "        if not os.path.exists(label_path):\n",
    "            return 0\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if not lines:\n",
    "            return 0\n",
    "        \n",
    "        classes = set()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                class_id = int(float(line.split()[0]))\n",
    "                classes.add(class_id)\n",
    "        \n",
    "        return hash(tuple(sorted(classes))) % 1000\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_files[idx]\n",
    "        label_path = self.label_files[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_tensor = F.to_tensor(image)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        parts = line.split()\n",
    "                        class_id = int(float(parts[0]))\n",
    "                        x_center, y_center, width, height = map(float, parts[1:])\n",
    "                        \n",
    "                        if width <= 0 or height <= 0:\n",
    "                            continue\n",
    "                        \n",
    "                        img_width, img_height = image.size\n",
    "                        x_min = (x_center - width/2) * img_width\n",
    "                        y_min = (y_center - height/2) * img_height\n",
    "                        x_max = (x_center + width/2) * img_width\n",
    "                        y_max = (y_center + height/2) * img_height\n",
    "                        \n",
    "                        x_min = max(0, min(x_min, img_width))\n",
    "                        y_min = max(0, min(y_min, img_height))\n",
    "                        x_max = max(0, min(x_max, img_width))\n",
    "                        y_max = max(0, min(y_max, img_height))\n",
    "                        \n",
    "                        if x_max > x_min and y_max > y_min:\n",
    "                            boxes.append([x_min, y_min, x_max, y_max])\n",
    "                            labels.append(class_id + 1)\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx])\n",
    "        }\n",
    "        \n",
    "        return image_tensor, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbacd0f",
   "metadata": {},
   "source": [
    "## 3. Model and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070faad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    \"\"\"Create Faster R-CNN model\"\"\"\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function\"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    filtered_images = []\n",
    "    filtered_targets = []\n",
    "    \n",
    "    for img, target in zip(images, targets):\n",
    "        if img.shape[0] != 3:\n",
    "            continue\n",
    "            \n",
    "        filtered_images.append(img)\n",
    "        \n",
    "        if len(target['boxes']) > 0:\n",
    "            valid_boxes = []\n",
    "            valid_labels = []\n",
    "            \n",
    "            for i, box in enumerate(target['boxes']):\n",
    "                x1, y1, x2, y2 = box\n",
    "                if x2 > x1 and y2 > y1:\n",
    "                    valid_boxes.append(box)\n",
    "                    valid_labels.append(target['labels'][i])\n",
    "            \n",
    "            if len(valid_boxes) > 0:\n",
    "                filtered_target = {\n",
    "                    'boxes': torch.stack(valid_boxes),\n",
    "                    'labels': torch.stack(valid_labels),\n",
    "                    'image_id': target['image_id']\n",
    "                }\n",
    "            else:\n",
    "                filtered_target = {\n",
    "                    'boxes': torch.zeros((0, 4), dtype=torch.float32),\n",
    "                    'labels': torch.zeros((0,), dtype=torch.int64),\n",
    "                    'image_id': target['image_id']\n",
    "                }\n",
    "        else:\n",
    "            filtered_target = {\n",
    "                'boxes': torch.zeros((0, 4), dtype=torch.float32),\n",
    "                'labels': torch.zeros((0,), dtype=torch.int64),\n",
    "                'image_id': target['image_id']\n",
    "            }\n",
    "        \n",
    "        filtered_targets.append(filtered_target)\n",
    "    \n",
    "    return list(filtered_images), list(filtered_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc03c43",
   "metadata": {},
   "source": [
    "## 4. Load Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"/root/ocr-project/First/Detection/ppe-dataset-clean/versions/1/ppe-detection-project-dataset-c/versions/1\"\n",
    "\n",
    "with open(os.path.join(dataset_root, 'data.yaml'), 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "class_names = data_config['names']\n",
    "num_classes = data_config['nc']\n",
    "\n",
    "combined_dataset = CombinedPPEDataset(dataset_root)\n",
    "\n",
    "print(f\"Classes: {num_classes} ({class_names})\")\n",
    "print(f\"Total dataset size: {len(combined_dataset)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0797503",
   "metadata": {},
   "source": [
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Configuration\n",
    "K_FOLDS = 5\n",
    "batch_size = 16\n",
    "gradient_accumulation_steps = 4\n",
    "num_epochs = 20\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "num_workers = 2\n",
    "use_mixed_precision = True\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - K-Folds: {K_FOLDS}\")\n",
    "print(f\"  - Batch Size: {batch_size}\")\n",
    "print(f\"  - Gradient Accumulation: {gradient_accumulation_steps}\")\n",
    "print(f\"  - Effective Batch Size: {batch_size * gradient_accumulation_steps}\")\n",
    "print(f\"  - Epochs per Fold: {num_epochs}\")\n",
    "print(f\"  - Mixed Precision: {use_mixed_precision}\")\n",
    "print(f\"  - Evaluation: Every 5 epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bd6c8",
   "metadata": {},
   "source": [
    "## 6. Initialize Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2127be2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=f\"ppe-detection-kfold-{K_FOLDS}\",\n",
    "    config={\n",
    "        'k_folds': K_FOLDS,\n",
    "        'batch_size': batch_size,\n",
    "        'gradient_accumulation_steps': gradient_accumulation_steps,\n",
    "        'effective_batch_size': batch_size * gradient_accumulation_steps,\n",
    "        'use_mixed_precision': use_mixed_precision,\n",
    "        'num_epochs': num_epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'momentum': momentum,\n",
    "        'weight_decay': weight_decay,\n",
    "        'num_classes': num_classes + 1,\n",
    "        'dataset_size': len(combined_dataset)\n",
    "    },\n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "wandb.define_metric(\"fold\")\n",
    "wandb.define_metric(\"epoch\")\n",
    "wandb.define_metric(\"train_loss\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"val_loss\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"learning_rate\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"mAP\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"precision\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"recall\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"f1_score\", step_metric=\"epoch\")\n",
    "\n",
    "for class_name in class_names:\n",
    "    wandb.define_metric(f\"mAP_{class_name}\", step_metric=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0898f1",
   "metadata": {},
   "source": [
    "## 7. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d274527",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, scaler=None):\n",
    "    \"\"\"Train for one epoch with gradient accumulation and mixed precision\"\"\"\n",
    "    model.train()\n",
    "    metric_logger = {}\n",
    "    \n",
    "    for idx, batch in enumerate(tqdm(data_loader, desc=f'Epoch {epoch}')):\n",
    "        if len(batch) == 2:\n",
    "            images, targets = batch\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "            \n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        # Mixed precision training\n",
    "        if use_mixed_precision and scaler is not None:\n",
    "            with autocast():\n",
    "                loss_dict = model(images, targets)\n",
    "        else:\n",
    "            loss_dict = model(images, targets)\n",
    "        \n",
    "        if isinstance(loss_dict, dict):\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            for k, v in loss_dict.items():\n",
    "                if k not in metric_logger:\n",
    "                    metric_logger[k] = []\n",
    "                metric_logger[k].append(v.item())\n",
    "        else:\n",
    "            losses = loss_dict\n",
    "        \n",
    "        # Scale loss for gradient accumulation\n",
    "        losses = losses / gradient_accumulation_steps\n",
    "        \n",
    "        # Clear gradients\n",
    "        if idx % gradient_accumulation_steps == 0:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Backward pass\n",
    "        if use_mixed_precision and scaler is not None:\n",
    "            scaler.scale(losses).backward()\n",
    "        else:\n",
    "            losses.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        if (idx + 1) % gradient_accumulation_steps == 0:\n",
    "            if use_mixed_precision and scaler is not None:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Clear memory\n",
    "        del images, targets, loss_dict, losses\n",
    "        if idx % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return {k: np.mean(v) for k, v in metric_logger.items()}\n",
    "\n",
    "def calculate_detection_metrics(predictions, targets, class_names, iou_threshold=0.5):\n",
    "    \"\"\"Calculate mAP, precision, recall, F1\"\"\"\n",
    "    metrics = {}\n",
    "    num_classes = len(class_names)\n",
    "    aps = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_name = class_names[class_idx]\n",
    "        pred_boxes = []\n",
    "        pred_scores = []\n",
    "        gt_boxes = []\n",
    "        \n",
    "        for pred in predictions:\n",
    "            if 'boxes' in pred and 'labels' in pred and 'scores' in pred:\n",
    "                class_mask = pred['labels'] == (class_idx + 1)\n",
    "                if class_mask.any():\n",
    "                    pred_boxes.append(pred['boxes'][class_mask])\n",
    "                    pred_scores.append(pred['scores'][class_mask])\n",
    "        \n",
    "        for target in targets:\n",
    "            if 'boxes' in target and 'labels' in target:\n",
    "                class_mask = target['labels'] == (class_idx + 1)\n",
    "                if class_mask.any():\n",
    "                    gt_boxes.append(target['boxes'][class_mask])\n",
    "        \n",
    "        if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "            all_pred_boxes = torch.cat(pred_boxes, dim=0)\n",
    "            all_pred_scores = torch.cat(pred_scores, dim=0)\n",
    "            all_gt_boxes = torch.cat(gt_boxes, dim=0)\n",
    "            \n",
    "            if len(all_pred_boxes) > 0 and len(all_gt_boxes) > 0:\n",
    "                ious = ops.box_iou(all_pred_boxes, all_gt_boxes)\n",
    "                sorted_indices = torch.argsort(all_pred_scores, descending=True)\n",
    "                sorted_ious = ious[sorted_indices]\n",
    "                \n",
    "                tp = torch.zeros(len(sorted_ious))\n",
    "                fp = torch.zeros(len(sorted_ious))\n",
    "                gt_matched = torch.zeros(len(all_gt_boxes), dtype=torch.bool)\n",
    "                \n",
    "                for i in range(len(sorted_ious)):\n",
    "                    max_iou, max_idx = torch.max(sorted_ious[i], dim=0)\n",
    "                    if max_iou >= iou_threshold and not gt_matched[max_idx]:\n",
    "                        tp[i] = 1\n",
    "                        gt_matched[max_idx] = True\n",
    "                    else:\n",
    "                        fp[i] = 1\n",
    "                \n",
    "                tp_cumsum = torch.cumsum(tp, dim=0)\n",
    "                fp_cumsum = torch.cumsum(fp, dim=0)\n",
    "                precision = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
    "                recall = tp_cumsum / len(all_gt_boxes)\n",
    "                \n",
    "                # 11-point interpolation AP\n",
    "                ap = 0\n",
    "                for t in torch.arange(0, 1.1, 0.1):\n",
    "                    if torch.sum(recall >= t) == 0:\n",
    "                        p = 0\n",
    "                    else:\n",
    "                        p = torch.max(precision[recall >= t])\n",
    "                    ap += p / 11\n",
    "                \n",
    "                metrics[f'mAP_{class_name}'] = ap.item()\n",
    "                aps.append(ap.item())\n",
    "                precisions.append(precision[-1].item() if len(precision) > 0 else 0)\n",
    "                recalls.append(recall[-1].item() if len(recall) > 0 else 0)\n",
    "            else:\n",
    "                metrics[f'mAP_{class_name}'] = 0\n",
    "                aps.append(0)\n",
    "                precisions.append(0)\n",
    "                recalls.append(0)\n",
    "        else:\n",
    "            metrics[f'mAP_{class_name}'] = 0\n",
    "            aps.append(0)\n",
    "            precisions.append(0)\n",
    "            recalls.append(0)\n",
    "    \n",
    "    metrics['mAP'] = np.mean(aps) if aps else 0\n",
    "    metrics['precision'] = np.mean(precisions) if precisions else 0\n",
    "    metrics['recall'] = np.mean(recalls) if recalls else 0\n",
    "    \n",
    "    if metrics['precision'] + metrics['recall'] > 0:\n",
    "        metrics['f1_score'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])\n",
    "    else:\n",
    "        metrics['f1_score'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluate(model, data_loader, device, class_names):\n",
    "    \"\"\"Simple evaluation (loss only)\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            if len(batch) == 2:\n",
    "                images, targets = batch\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            if len(images) == 0:\n",
    "                continue\n",
    "                \n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            model.train()\n",
    "            if use_mixed_precision:\n",
    "                with autocast():\n",
    "                    loss_dict = model(images, targets)\n",
    "            else:\n",
    "                loss_dict = model(images, targets)\n",
    "            model.eval()\n",
    "            \n",
    "            if isinstance(loss_dict, dict):\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "            else:\n",
    "                losses = loss_dict\n",
    "                \n",
    "            total_loss += losses.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            del images, targets, loss_dict, losses\n",
    "            if num_batches % 25 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    metrics = {'val_loss': total_loss / num_batches if num_batches > 0 else 0}\n",
    "    for class_name in class_names:\n",
    "        metrics[f'mAP_{class_name}'] = 0.0\n",
    "    metrics.update({'mAP': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluate_full(model, data_loader, device, class_names):\n",
    "    \"\"\"Full evaluation with metrics (run every 5 epochs)\"\"\"\n",
    "    print(\"  Running full evaluation...\")\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Full evaluation\"):\n",
    "            if len(batch) == 2:\n",
    "                images, targets = batch\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            if len(images) == 0:\n",
    "                continue\n",
    "                \n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            predictions = model(images)\n",
    "            all_predictions.extend(predictions)\n",
    "            all_targets.extend(targets)\n",
    "            \n",
    "            del images, targets, predictions\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    metrics = calculate_detection_metrics(all_predictions, all_targets, class_names)\n",
    "    del all_predictions, all_targets\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e35c1",
   "metadata": {},
   "source": [
    "## 8. K-Fold Cross Validation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ecc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "indices = list(range(len(combined_dataset)))\n",
    "stratified_labels = combined_dataset.stratified_labels\n",
    "\n",
    "all_fold_results = []\n",
    "\n",
    "print(\"Starting Stratified K-Fold Cross Validation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(stratified_kfold.split(indices, stratified_labels)):\n",
    "    print(f\"\\nFold {fold+1}/{K_FOLDS}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Create datasets for this fold\n",
    "    train_subset = Subset(combined_dataset, train_idx)\n",
    "    val_subset = Subset(combined_dataset, val_idx)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_subset)}\")\n",
    "    print(f\"Validation samples: {len(val_subset)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_subset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_subset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Create model and optimizer\n",
    "    model = get_model(num_classes + 1)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    # Scheduler: reduce LR by 50% every 10 epochs\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    scaler = GradScaler() if use_mixed_precision else None\n",
    "    \n",
    "    # Training loop for this fold\n",
    "    fold_val_losses = []\n",
    "    fold_metrics = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_one_epoch(model, optimizer, train_loader, device, epoch+1, scaler)\n",
    "        \n",
    "        # Evaluate every 5 epochs or at the end\n",
    "        if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n",
    "            val_metrics = evaluate_full(model, val_loader, device, class_names)\n",
    "            print(f\"  Epoch {epoch+1}/{num_epochs}: Train Loss: {sum(train_metrics.values()):.4f}, mAP: {val_metrics['mAP']:.3f}\")\n",
    "        else:\n",
    "            val_metrics = evaluate(model, val_loader, device, class_names)\n",
    "            print(f\"  Epoch {epoch+1}/{num_epochs}: Train Loss: {sum(train_metrics.values()):.4f}, Val Loss: {val_metrics['val_loss']:.4f}\")\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        total_train_loss = sum(train_metrics.values())\n",
    "        fold_val_losses.append(val_metrics.get('val_loss', 0))\n",
    "        fold_metrics.append(val_metrics)\n",
    "        \n",
    "        # Log to wandb\n",
    "        log_dict = {\n",
    "            'fold': fold+1,\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': total_train_loss,\n",
    "            'val_loss': val_metrics.get('val_loss', 0),\n",
    "            'learning_rate': current_lr,\n",
    "            'mAP': val_metrics['mAP'],\n",
    "            'precision': val_metrics['precision'],\n",
    "            'recall': val_metrics['recall'],\n",
    "            'f1_score': val_metrics['f1_score']\n",
    "        }\n",
    "        \n",
    "        for class_name in class_names:\n",
    "            log_dict[f'mAP_{class_name}'] = val_metrics[f'mAP_{class_name}']\n",
    "        \n",
    "        wandb.log(log_dict)\n",
    "        \n",
    "        del train_metrics, val_metrics\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save model for this fold\n",
    "    os.makedirs('kfold-model', exist_ok=True)\n",
    "    model_path = f'kfold-model/fasterrcnn_ppe_fold{fold+1}.pth'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    wandb.save(model_path)\n",
    "    \n",
    "    # Store results\n",
    "    fold_result = {\n",
    "        'fold': fold+1,\n",
    "        'train_samples': len(train_subset),\n",
    "        'val_samples': len(val_subset),\n",
    "        'final_metrics': fold_metrics[-1],\n",
    "        'model_path': model_path\n",
    "    }\n",
    "    all_fold_results.append(fold_result)\n",
    "    \n",
    "    print(f\"  Fold {fold+1} completed - Final mAP: {fold_metrics[-1]['mAP']:.3f}\")\n",
    "    \n",
    "    del model, optimizer, lr_scheduler, scaler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nK-Fold Cross Validation completed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac6dfb",
   "metadata": {},
   "source": [
    "## 9. Aggregate Results and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall metrics\n",
    "metric_keys = ['mAP', 'precision', 'recall', 'f1_score']\n",
    "overall_metrics = {}\n",
    "\n",
    "for metric in metric_keys:\n",
    "    values = [result['final_metrics'][metric] for result in all_fold_results]\n",
    "    overall_metrics[f'{metric}_mean'] = np.mean(values)\n",
    "    overall_metrics[f'{metric}_std'] = np.std(values)\n",
    "\n",
    "# Per-class mAP\n",
    "for class_name in class_names:\n",
    "    values = [result['final_metrics'][f'mAP_{class_name}'] for result in all_fold_results]\n",
    "    overall_metrics[f'mAP_{class_name}_mean'] = np.mean(values)\n",
    "    overall_metrics[f'mAP_{class_name}_std'] = np.std(values)\n",
    "\n",
    "# Log overall results\n",
    "wandb.log(overall_metrics)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nOverall Performance (Mean ± Std):\")\n",
    "print(f\"  - mAP: {overall_metrics['mAP_mean']:.3f} ± {overall_metrics['mAP_std']:.3f}\")\n",
    "print(f\"  - Precision: {overall_metrics['precision_mean']:.3f} ± {overall_metrics['precision_std']:.3f}\")\n",
    "print(f\"  - Recall: {overall_metrics['recall_mean']:.3f} ± {overall_metrics['recall_std']:.3f}\")\n",
    "print(f\"  - F1 Score: {overall_metrics['f1_score_mean']:.3f} ± {overall_metrics['f1_score_std']:.3f}\")\n",
    "\n",
    "print(f\"\\nPer-Class mAP:\")\n",
    "for class_name in class_names:\n",
    "    mean_val = overall_metrics[f'mAP_{class_name}_mean']\n",
    "    std_val = overall_metrics[f'mAP_{class_name}_std']\n",
    "    print(f\"  - {class_name}: {mean_val:.3f} ± {std_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d046d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# mAP per fold\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "fold_maps = [result['final_metrics']['mAP'] for result in all_fold_results]\n",
    "ax1.bar(range(1, K_FOLDS+1), fold_maps, color='skyblue')\n",
    "ax1.set_title('mAP per Fold', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Fold')\n",
    "ax1.set_ylabel('mAP')\n",
    "\n",
    "# Per-class mAP\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "class_means = [overall_metrics[f'mAP_{c}_mean'] for c in class_names]\n",
    "class_stds = [overall_metrics[f'mAP_{c}_std'] for c in class_names]\n",
    "ax2.bar(class_names, class_means, yerr=class_stds, capsize=5, color='lightgreen')\n",
    "ax2.set_title('Per-Class mAP', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('mAP')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Overall metrics\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "metrics_names = ['mAP', 'Precision', 'Recall', 'F1 Score']\n",
    "metrics_means = [overall_metrics[f'{m.lower()}_mean'] for m in metrics_names]\n",
    "ax3.bar(metrics_names, metrics_means, color='gold')\n",
    "ax3.set_title('Overall Metrics', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "wandb.log({\"kfold_results\": wandb.Image(fig)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce556d4",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c70b5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_file = f\"kfold_results_{timestamp}.json\"\n",
    "\n",
    "results_summary = {\n",
    "    'k_folds': K_FOLDS,\n",
    "    'total_samples': len(combined_dataset),\n",
    "    'overall_metrics': overall_metrics,\n",
    "    'fold_results': all_fold_results,\n",
    "    'class_names': class_names,\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "wandb.save(results_file)\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
