{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"./_output_/K-Fold-Training/fold_5_exp/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb90203",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./ppe-detection-project-dataset-c/versions/1\"\n",
    "test_img_dir = os.path.join(base_path, \"test/images\")\n",
    "test_label_dir = os.path.join(base_path, \"test/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_images = [f for f in os.listdir(test_img_dir) if f.endswith((\".jpg\", \".png\"))]\n",
    "sample_images = random.sample(all_images, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = os.path.join(\"./\", \"config.yaml\")\n",
    "\n",
    "\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "class_names = config[\"names\"]\n",
    "\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- อ่าน config.yaml ---\n",
    "yaml_path = os.path.join(\"./\", \"config.yaml\")\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "class_names = config[\"names\"]\n",
    "\n",
    "# --- วน loop แสดงรูป ---\n",
    "for img_name in sample_images:\n",
    "    img_path = os.path.join(test_img_dir, img_name)\n",
    "    label_path = os.path.join(test_label_dir, os.path.splitext(img_name)[0] + \".txt\")\n",
    "    \n",
    "    # อ่านภาพ\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # --- Ground Truth ---\n",
    "    gt_img = img_rgb.copy()\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                cls, x, y, w, h = map(float, line.strip().split())\n",
    "                h_img, w_img, _ = gt_img.shape\n",
    "                x1 = int((x - w/2) * w_img)\n",
    "                y1 = int((y - h/2) * h_img)\n",
    "                x2 = int((x + w/2) * w_img)\n",
    "                y2 = int((y + h/2) * h_img)\n",
    "                cls_name = class_names[int(cls)]\n",
    "                # วาดกรอบเขียว\n",
    "                cv2.rectangle(gt_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                # ใส่ชื่อ class\n",
    "                cv2.putText(gt_img, cls_name, (x1, y1-5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "    \n",
    "    # --- Prediction ---\n",
    "    results = model(img_path, imgsz=640, conf=0.25)\n",
    "    pred_img = img_rgb.copy()\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        scores = r.boxes.conf.cpu().numpy()\n",
    "        pred_classes = r.boxes.cls.cpu().numpy()\n",
    "        for box, cls_idx, conf in zip(boxes, pred_classes, scores):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cls_name = r.names[int(cls_idx)]\n",
    "            text = f\"{cls_name} {conf:.2f}\"\n",
    "            # วาดกรอบแดง\n",
    "            cv2.rectangle(pred_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            # ใส่ชื่อ class + confidence\n",
    "            cv2.putText(pred_img, text, (x1, y1-5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "    # --- แสดงคู่ภาพ ---\n",
    "    fig, axs = plt.subplots(1,2, figsize=(12,6))\n",
    "    axs[0].imshow(gt_img)\n",
    "    axs[0].set_title(\"Ground Truth\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(pred_img)\n",
    "    axs[1].set_title(\"Prediction\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics torch \n",
    "%pip install YOLOv8-Explainer \n",
    "%pip install grad-cam==1.4.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4344b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "class YOLOv8GradCAM:\n",
    "    def __init__(self, model, target_layer_idx=-1):\n",
    "        self.model = model\n",
    "        self.target_layer_idx = target_layer_idx\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        # Register hooks\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            if grad_output[0] is not None:\n",
    "                self.gradients = grad_output[0]\n",
    "\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "\n",
    "        # Handle negative indexing\n",
    "        if self.target_layer_idx < 0:\n",
    "            layer_idx = len(self.model) + self.target_layer_idx\n",
    "        else:\n",
    "            layer_idx = self.target_layer_idx\n",
    "\n",
    "        # Ensure layer index is valid\n",
    "        layer_idx = max(0, min(layer_idx, len(self.model) - 1))\n",
    "\n",
    "        # Find a suitable layer (skip problematic layer types)\n",
    "        suitable_layer_found = False\n",
    "        for offset in [0, -1, 1, -2, 2]:\n",
    "            try_idx = layer_idx + offset\n",
    "            if 0 <= try_idx < len(self.model):\n",
    "                target_layer = self.model[try_idx]\n",
    "                layer_type = type(target_layer).__name__\n",
    "\n",
    "                if layer_type not in [\n",
    "                    \"Upsample\",\n",
    "                    \"AdaptiveAvgPool2d\",\n",
    "                    \"Flatten\",\n",
    "                    \"Dropout\",\n",
    "                ]:\n",
    "                    layer_idx = try_idx\n",
    "                    suitable_layer_found = True\n",
    "                    break\n",
    "\n",
    "        if not suitable_layer_found:\n",
    "            print(\n",
    "                f\"Warning: No suitable layer found near index {self.target_layer_idx}\"\n",
    "            )\n",
    "            layer_idx = min(5, len(self.model) - 1)\n",
    "\n",
    "        target_layer = self.model[layer_idx]\n",
    "        handle1 = target_layer.register_backward_hook(backward_hook)\n",
    "        handle2 = target_layer.register_forward_hook(forward_hook)\n",
    "        self.hook_handles.extend([handle1, handle2])\n",
    "\n",
    "        print(f\"Registered hooks on layer {layer_idx}: {type(target_layer).__name__}\")\n",
    "        self.actual_layer_idx = layer_idx\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        return self.model(input_tensor)\n",
    "\n",
    "    def generate_cam(self, input_tensor, class_idx=None):\n",
    "        input_tensor.requires_grad_(True)\n",
    "\n",
    "        try:\n",
    "            output = self.forward(input_tensor)\n",
    "\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                output = output[0]\n",
    "\n",
    "            if len(output.shape) > 2:\n",
    "                pooled_output = torch.mean(\n",
    "                    output.view(output.size(0), output.size(1), -1), dim=2\n",
    "                )\n",
    "                target_score = torch.mean(pooled_output)\n",
    "            else:\n",
    "                target_score = torch.mean(output)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Forward pass error: {e}\")\n",
    "            return np.random.rand(64, 64)\n",
    "\n",
    "        try:\n",
    "            self.model.zero_grad()\n",
    "            target_score.backward(retain_graph=True)\n",
    "\n",
    "            if self.gradients is None or self.activations is None:\n",
    "                print(\"Warning: No gradients or activations captured\")\n",
    "                return np.random.rand(64, 64)\n",
    "\n",
    "            gradients = self.gradients.detach()\n",
    "            activations = self.activations.detach()\n",
    "\n",
    "            if len(gradients.shape) == 4:\n",
    "                gradients = gradients[0]\n",
    "                activations = activations[0]\n",
    "\n",
    "                weights = torch.mean(gradients.view(gradients.size(0), -1), dim=1)\n",
    "\n",
    "                cam = torch.zeros(activations.shape[1:], dtype=torch.float32)\n",
    "                for i, w in enumerate(weights):\n",
    "                    if i < activations.size(0):\n",
    "                        cam += w * activations[i]\n",
    "            else:\n",
    "                cam = (\n",
    "                    torch.mean(activations[0], dim=0)\n",
    "                    if len(activations.shape) > 2\n",
    "                    else activations[0]\n",
    "                )\n",
    "\n",
    "            cam = F.relu(cam)\n",
    "            if cam.max() > cam.min():\n",
    "                cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "            else:\n",
    "                cam = torch.zeros_like(cam)\n",
    "\n",
    "            cam_numpy = cam.numpy()\n",
    "            cam_numpy = 1.0 - cam_numpy  # Invert\n",
    "\n",
    "            return cam_numpy\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Backward pass error: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "            return np.random.rand(64, 64)\n",
    "\n",
    "    def cleanup(self):\n",
    "        for handle in self.hook_handles:\n",
    "            handle.remove()\n",
    "        self.hook_handles = []\n",
    "\n",
    "\n",
    "def generate_t8_gradcam(\n",
    "    image_path, model_path=\"best.pt\", device=\"cpu\", class_names=None\n",
    "):\n",
    "    \"\"\"Generate only t_8 Grad-CAM visualization\"\"\"\n",
    "\n",
    "    # Load model and image\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    yolo = YOLO(model_path)\n",
    "    device = torch.device(device)\n",
    "    yolo.model.to(device)\n",
    "\n",
    "    # Load and preprocess image\n",
    "    print(f\"Loading image from: {image_path}\")\n",
    "    image_bgr = cv2.imread(image_path)\n",
    "    if image_bgr is None:\n",
    "        raise ValueError(f\"Could not load image from {image_path}\")\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    print(f\"Original image shape: {image_rgb.shape}\")\n",
    "\n",
    "    # Prepare input tensor\n",
    "    input_tensor = (\n",
    "        torch.from_numpy(image_rgb.transpose(2, 0, 1)).float().unsqueeze(0) / 255.0\n",
    "    )\n",
    "    input_tensor = F.interpolate(\n",
    "        input_tensor, size=(640, 640), mode=\"bilinear\", align_corners=False\n",
    "    )\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    print(f\"Input tensor shape: {input_tensor.shape}\")\n",
    "\n",
    "    # Get backbone layers\n",
    "    try:\n",
    "        backbone_layers = yolo.model.model[:11]\n",
    "        print(f\"Using backbone layers: {len(backbone_layers)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing backbone layers: {e}\")\n",
    "        backbone_layers = list(yolo.model.model.children())[:11]\n",
    "\n",
    "    # Run initial prediction\n",
    "    with torch.no_grad():\n",
    "        results = yolo(image_path)\n",
    "        if results and len(results[0].boxes) > 0:\n",
    "            detected_classes = results[0].boxes.cls.cpu().numpy()\n",
    "            confidences = results[0].boxes.conf.cpu().numpy()\n",
    "            print(f\"\\nDetected {len(detected_classes)} objects:\")\n",
    "            for i, (cls_idx, conf) in enumerate(zip(detected_classes, confidences)):\n",
    "                if class_names and int(cls_idx) < len(class_names):\n",
    "                    class_name = class_names[int(cls_idx)]\n",
    "                else:\n",
    "                    class_name = f\"Class_{int(cls_idx)}\"\n",
    "                print(f\"  {i + 1}. {class_name} (conf: {conf:.3f})\")\n",
    "\n",
    "    # Generate t_8 Grad-CAM\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Generating t_8 (Layer 8) Grad-CAM...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    gradcam_model = YOLOv8GradCAM(backbone_layers, target_layer_idx=8)\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        cam = gradcam_model.generate_cam(input_tensor)\n",
    "\n",
    "    # Ensure CAM is valid\n",
    "    if cam is None or cam.size == 0:\n",
    "        print(f\"Warning: Empty CAM\")\n",
    "        cam = np.ones((64, 64)) * 0.5\n",
    "\n",
    "    # Resize CAM to original image size\n",
    "    cam_resized = cv2.resize(cam, (image_rgb.shape[1], image_rgb.shape[0]))\n",
    "    cam_normalized = np.uint8(255 * np.clip(cam_resized, 0, 1))\n",
    "\n",
    "    # Create heatmap\n",
    "    heatmap = cv2.applyColorMap(cam_normalized, cv2.COLORMAP_JET)\n",
    "    heatmap_rgb = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create overlay\n",
    "    overlay = cv2.addWeighted(image_rgb, 0.6, heatmap_rgb, 0.4, 0)\n",
    "\n",
    "    # Cleanup\n",
    "    gradcam_model.cleanup()\n",
    "    del gradcam_model\n",
    "\n",
    "    # Display result\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Original image\n",
    "    axes[0].imshow(image_rgb)\n",
    "    axes[0].set_title(\"Original Image\", fontsize=14, weight=\"bold\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Heatmap only\n",
    "    axes[1].imshow(heatmap_rgb)\n",
    "    axes[1].set_title(\"t_8 Heatmap\\n(Semantic Features)\", fontsize=14, weight=\"bold\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    # Overlay\n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(\n",
    "        \"t_8 Overlay\\n(Layer 8 - High-Level Features)\", fontsize=14, weight=\"bold\"\n",
    "    )\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"YOLOv8 Grad-CAM - Layer 8 (t_8) Visualization\", fontsize=16, y=1.02)\n",
    "    # plt.show()\n",
    "\n",
    "    # Save result\n",
    "    import os\n",
    "\n",
    "    os.makedirs(\"t8_output\", exist_ok=True)\n",
    "    cv2.imwrite(\"t8_output/t8_overlay.jpg\", cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(\n",
    "        \"t8_output/t8_heatmap.jpg\", cv2.cvtColor(heatmap_rgb, cv2.COLOR_RGB2BGR)\n",
    "    )\n",
    "    print(\"\\nSaved t_8 results to 't8_output/' folder\")\n",
    "\n",
    "    return {\n",
    "        \"cam\": cam_resized,\n",
    "        \"overlay\": overlay,\n",
    "        \"heatmap\": heatmap_rgb,\n",
    "        \"original\": image_rgb,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7527a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read best.pt model from _output_/K-Fold-Training/Fold-n/best.pt\n",
    "\n",
    "model_path = \"./best.pt\"\n",
    "image_path = \"./ppe-detection-project-dataset-c/versions/1/test/images/0002.jpg\"\n",
    "device = \"cpu\"  # or \"cuda\" if GPU is available\n",
    "generate_t8_gradcam(image_path, model_path, device, class_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- อ่าน config.yaml ---\n",
    "yaml_path = os.path.join(\"./\", \"config.yaml\")\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "class_names = config[\"names\"]\n",
    "\n",
    "# --- วน loop แสดงรูป ---\n",
    "for img_name in sample_images:\n",
    "    img_path = os.path.join(test_img_dir, img_name)\n",
    "    label_path = os.path.join(test_label_dir, os.path.splitext(img_name)[0] + \".txt\")\n",
    "    \n",
    "    # อ่านภาพ\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # --- Ground Truth ---\n",
    "    gt_img = img_rgb.copy()\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                cls, x, y, w, h = map(float, line.strip().split())\n",
    "                h_img, w_img, _ = gt_img.shape\n",
    "                x1 = int((x - w/2) * w_img)\n",
    "                y1 = int((y - h/2) * h_img)\n",
    "                x2 = int((x + w/2) * w_img)\n",
    "                y2 = int((y + h/2) * h_img)\n",
    "                cls_name = class_names[int(cls)]\n",
    "                # วาดกรอบเขียว\n",
    "                cv2.rectangle(gt_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                # ใส่ชื่อ class\n",
    "                cv2.putText(gt_img, cls_name, (x1, y1-5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "    \n",
    "    # --- Prediction ---\n",
    "    results = model(img_path, imgsz=640, conf=0.25)\n",
    "    pred_img = img_rgb.copy()\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        scores = r.boxes.conf.cpu().numpy()\n",
    "        pred_classes = r.boxes.cls.cpu().numpy()\n",
    "        for box, cls_idx, conf in zip(boxes, pred_classes, scores):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cls_name = r.names[int(cls_idx)]\n",
    "            text = f\"{cls_name} {conf:.2f}\"\n",
    "            # วาดกรอบแดง\n",
    "            cv2.rectangle(pred_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            # ใส่ชื่อ class + confidence\n",
    "            cv2.putText(pred_img, text, (x1, y1-5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "    # --- Grad-CAM Overlay (Layer t_8) ---\n",
    "    gradcam_result = generate_t8_gradcam(\n",
    "        img_path, \n",
    "        model_path=\"best.pt\", \n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\", \n",
    "        class_names=class_names\n",
    "    )\n",
    "    overlay_img = gradcam_result[\"overlay\"]\n",
    "\n",
    "    # --- แสดงภาพ 3 คอลัมน์ ---\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    axs[0].imshow(gt_img)\n",
    "    axs[0].set_title(\"Ground Truth\", fontsize=14, weight=\"bold\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(pred_img)\n",
    "    axs[1].set_title(\"Prediction\", fontsize=14, weight=\"bold\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    axs[2].imshow(overlay_img)\n",
    "    axs[2].set_title(\"t_8 Overlay\\n(Layer 8 - High-Level Features)\", fontsize=14, weight=\"bold\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
